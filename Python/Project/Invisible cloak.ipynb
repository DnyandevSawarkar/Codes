{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-777af6424260>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;31m## Segment the red color part out of the frame using bitwise and with the inverted mask\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     \u001b[0mres1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbitwise_and\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;31m## Create image showing static background frame pixels only for the masked region\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "## Preparation for writing the ouput video\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('output.avi', fourcc, 20.0, (640, 480))\n",
    "\n",
    "##reading from the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "## Allow the system to sleep for 3 seconds before the webcam starts\n",
    "time.sleep(3)\n",
    "count = 0\n",
    "background = 0\n",
    "\n",
    "## Capture the background in range of 60\n",
    "for i in range(60):\n",
    "    ret, background = cap.read()\n",
    "background = np.flip(background, axis=1)\n",
    "\n",
    "## Read every frame from the webcam, until the camera is open\n",
    "while (cap.isOpened()):\n",
    "    ret, img = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    count += 1\n",
    "    img = np.flip(img, axis=1)\n",
    "\n",
    "    ## Convert the color space from BGR to HSV\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    ## Generat masks to detect red color\n",
    "    \n",
    "    ##YOU CAN CHANGE THE COLOR VALUE BELOW ACCORDING TO YOUR CLOTH COLOR\n",
    "    lower_red = np.array([44, 54, 63])\n",
    "    upper_red = np.array([71, 255,255])\n",
    "    mask1 = cv2.inRange(hsv, lower_red, upper_red)\n",
    "\n",
    "    lower_red = np.array([170, 120, 70])\n",
    "    upper_red = np.array([180, 255, 255])\n",
    "    mask2 = cv2.inRange(hsv, lower_red, upper_red)\n",
    "\n",
    "    mask1 = mask1 + mask2\n",
    "\n",
    "    ## Open and Dilate the mask image\n",
    "    mask1 = cv2.morphologyEx(mask1, cv2.MORPH_OPEN, np.ones((3, 3), np.uint8))\n",
    "    mask1 = cv2.morphologyEx(mask1, cv2.MORPH_DILATE, np.ones((3, 3), np.uint8))\n",
    "\n",
    "    ## Create an inverted mask to segment out the red color from the frame\n",
    "    mask2 = cv2.bitwise_not(mask1)\n",
    "\n",
    "    ## Segment the red color part out of the frame using bitwise and with the inverted mask\n",
    "    res1 = cv2.bitwise_and(img, img, mask=mask2)\n",
    "\n",
    "    ## Create image showing static background frame pixels only for the masked region\n",
    "    res2 = cv2.bitwise_and(background, background, mask=mask1)\n",
    "\n",
    "    ## Generating the final output and writing\n",
    "    finalOutput = cv2.addWeighted(res1, 1, res2, 1, 0)\n",
    "    out.write(finalOutput)\n",
    "    cv2.imshow(\"magic\", finalOutput)\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#colors code\n",
    "\n",
    "#skin color Values\n",
    "#lower_red = np.array([0, 0, 70])\n",
    "#upper_red = np.array([100, 255,255])\n",
    "# mask1 = cv2.inRange(hsv, lower_red, upper_red)\n",
    "#-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FourCC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FourCC is a 4-byte code used to specify the video codec. The list of available codes can be found in fourcc.org. It is platform dependent. The following codecs work fine for me.\n",
    "\n",
    "1. In Fedora: \n",
    "DIVX, XVID, MJPG, X264, WMV1, WMV2. (XVID is more preferable. MJPG results in high size video. X264 gives very small size video)\n",
    "\n",
    "2. In Windows: \n",
    "DIVX (More to be tested and added)\n",
    "\n",
    "3. In OSX: \n",
    "MJPG (.mp4), DIVX (.avi), X264 (.mkv)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Webcam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cap.read() returns a bool (True/False). If frame is read correctly, it will be True. So you can check end of the video by checking this return value.\n",
    "\n",
    "Sometimes, cap may not have initialized the capture. In that case, this code shows error. You can check whether it is initialized or not by the method cap.isOpened(). If it is True, OK. Otherwise open it using cap.open()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Masking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mask1 = cv2.inRange(hsv, lower_red, upper_red)\n",
    "\n",
    "Here, it basically sets the threshold to red colour (since we are using red colour...if we change the parameters to blue to some other colour it we set itself accordingly) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Morphological Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Morphological transformations are some simple operations based on the image shape. It is normally performed on binary images. It needs two inputs, one is our original image, second one is called structuring element or kernel which decides the nature of operation. Two basic morphological operators are Erosion and Dilation. Then its variant forms like Opening, Closing, Gradient etc also comes into play. \n",
    "\n",
    "1. Erosion\n",
    "\n",
    "The basic idea of erosion is just like soil erosion only, it erodes away the boundaries of foreground object (Always try to keep foreground in white). So what does it do? The kernel slides through the image (as in 2D convolution). A pixel in the original image (either 1 or 0) will be considered 1 only if all the pixels under the kernel is 1, otherwise it is eroded (made to zero).\n",
    "\n",
    "So what happends is that, all the pixels near boundary will be discarded depending upon the size of kernel. So the thickness or size of the foreground object decreases or simply white region decreases in the image. It is useful for removing small white noises, detach two connected objects etc.\n",
    "\n",
    "2. Dilation\n",
    "\n",
    "It is just opposite of erosion. Here, a pixel element is ‘1’ if atleast one pixel under the kernel is ‘1’. So it increases the white region in the image or size of foreground object increases. Normally, in cases like noise removal, erosion is followed by dilation. Because, erosion removes white noises, but it also shrinks our object. So we dilate it. Since noise is gone, they won’t come back, but our object area increases. It is also useful in joining broken parts of an object.\n",
    "\n",
    "3. Opening\n",
    "\n",
    "Opening is just another name of erosion followed by dilation. It is useful in removing noise\n",
    "\n",
    "4. Closing\n",
    "\n",
    "Closing is reverse of Opening, Dilation followed by Erosion. It is useful in closing small holes inside the foreground objects, or small black points on the object.\n",
    "\n",
    "5. Morphological Gradient\n",
    "\n",
    "It is the difference between dilation and erosion of an image.\n",
    "\n",
    "The result will look like the outline of the object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RGB to HSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RGB values are highly sensitive to illumination. Hence even though the cloak is of red color there might be some areas where, due-to shadow, Red channel values of the corresponding pixels are quite low.\n",
    "\n",
    "The right approach is to transform the color space of our image from RGB to HSV (Hue – Saturation – Value).\n",
    "\n",
    "--The HSV color space represents colors using three values\n",
    "\n",
    "1. Hue \n",
    "This channel encodes color color information. Hue can be thought of an angle where 0 degree corresponds to the red color, 120 degrees corresponds to the green color, and 240 degrees corresponds to the blue color.\n",
    "\n",
    "2. Saturation \n",
    "This channel encodes the intensity/purity of color. For example, pink is less saturated than red.\n",
    "\n",
    "3. Value\n",
    "This channel encodes the brightness of color. Shading and gloss components of an image appear in this channel.\n",
    "Unlike RGB which is defined in relation to primary colors, HSV is defined in a way that is similar to how humans perceive color.\n",
    "\n",
    "For our application, the major advantage of using the HSV color space is that the color/tint/wavelength is represented by just the Hue component."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps:\n",
    " 1. Capture and store the background frame\n",
    " 2. Detect the red colour using the colour detection method\n",
    " 3. Segment out the red colour from the feed and replace it by the background image\n",
    " 4. Augment the final output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('output.avi', fourcc, 20.0, (640, 480))\n",
    "\n",
    "##reading from the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "## Allow the system to sleep for 3 seconds before the webcam starts\n",
    "time.sleep(3)\n",
    "count = 0\n",
    "background = 0\n",
    "\n",
    "## Capture the background in range of 60\n",
    "for i in range(60):\n",
    "    ret, background = cap.read()\n",
    "background = np.flip(background, axis=1)\n",
    "while (cap.isOpened()):\n",
    "    ret, img = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    count += 1\n",
    "    img = np.flip(img, axis=1)\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    lower_red = np.array([0, 120, 50])\n",
    "    upper_red = np.array([10, 255,255])\n",
    "    mask1 = cv2.inRange(hsv, lower_red, upper_red)\n",
    "    lower_red = np.array([170, 120, 70])\n",
    "    upper_red = np.array([180, 255, 255])\n",
    "    mask2 = cv2.inRange(hsv, lower_red, upper_red)\n",
    "    mask1 = mask1 + mask2\n",
    "    mask1 = cv2.morphologyEx(mask1, cv2.MORPH_OPEN, np.ones((3, 3), np.uint8))\n",
    "    mask1 = cv2.morphologyEx(mask1, cv2.MORPH_DILATE, np.ones((3, 3), np.uint8))\n",
    "    mask2 = cv2.bitwise_not(mask1)\n",
    "    res1 = cv2.bitwise_and(img, img, mask=mask2)\n",
    "    res2 = cv2.bitwise_and(background, background, mask=mask1)\n",
    "    finalOutput = cv2.addWeighted(res1, 1, res2, 1, 0)\n",
    "    out.write(finalOutput)\n",
    "    cv2.imshow(\"magic\", finalOutput)\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
